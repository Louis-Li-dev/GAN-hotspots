{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tqdm\n",
    "# %pip install python-dotenv\n",
    "# %pip install torch==2.4.0+cu118\n",
    "# %pip install scikit_learn==1.2.2\n",
    "# %pip install ipython\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install tabulate\n",
    "# %pip install scipy\n",
    "# %pip install git+https://github.com/Louis-Li-dev/ML_tool_kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.join(os.getcwd(), '..')\n",
    "if parent_dir not in sys.path: sys.path.append(parent_dir)\n",
    "from utility.data_utils import *\n",
    "from utility.visuals import *\n",
    "from dotenv import load_dotenv\n",
    "from model.CNN import ConditionalSegmentationVAE\n",
    "from mkit.torch_support.tensor_utils import xy_to_tensordataset\n",
    "from torch import nn\n",
    "from IPython.display import clear_output\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR): raise FileNotFoundError(\"Make sure the data directory is correctly placed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_files(DATA_DIR)\n",
    "\n",
    "return_list = []\n",
    "file = files[0]\n",
    "city_name = file.split('\\\\')[-1].split('.csv')[0].split('_')[0]\n",
    "\n",
    "path_name = process_and_transform_data(file, resolution=.5, overwrite=True)\n",
    "with open(path_name, 'rb') as f:\n",
    "    result_dict = pickle.load(f)\n",
    "labels = result_dict['labels']\n",
    "encoder = result_dict['encoder']\n",
    "MAX_LEN = result_dict['max length']\n",
    "file_name = result_dict['file name']\n",
    "WIDTH = result_dict['width']\n",
    "HEIGHT = result_dict['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x y splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "unique_labels = [u for u in labels if np.array(np.where(u != 0)).T.shape[0] > 1]\n",
    "\n",
    "\n",
    "train_labels, test_labels = train_test_split(np.expand_dims(np.array(unique_labels), axis=1), test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming 'train_labels' is the data you're transforming\n",
    "pca = PCA(n_components=0.96)  # Retain 96% of variance for PCA\n",
    "pca.fit(train_labels.reshape(train_labels.shape[0], -1))\n",
    "transformed = pca.transform(train_labels.reshape(train_labels.shape[0], -1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "knn = NearestNeighbors(n_jobs=-1)\n",
    "knn.fit(transformed)\n",
    "features = []\n",
    "for ele in transformed:\n",
    "    indices = knn.kneighbors(ele.reshape(1, -1), n_neighbors=3, return_distance=False)[0]\n",
    "    features.append(transformed[indices])\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "noise_dim = 100\n",
    "condition_dim = features.shape[-1]\n",
    "batch_size = 32\n",
    "num_epochs = 7000\n",
    "lr = 0.0002  # Learning rate\n",
    "betas = (0.5, 0.999)  # Beta parameters for Adam optimizer\n",
    "output_dim = transformed.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axes = axes.flatten()\n",
    "axes[0].imshow(test_labels[0][0])\n",
    "x, y, _, _ = get_x_y(test_labels, MAX_LEN=MAX_LEN, encoder=encoder)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "axes[1].imshow(x[0][0])\n",
    "axes[2].imshow(y[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming 'train_labels' is the data you're transforming\n",
    "test_pca = PCA(n_components=0.96)  # Retain 96% of variance for PCA\n",
    "test_pca.fit(x.reshape(x.shape[0], -1))\n",
    "test_transformed = pca.transform(x.reshape(x.shape[0], -1))\n",
    "test_transformed.shape, x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_features = []\n",
    "for ele in test_transformed:\n",
    "    indices = knn.kneighbors(ele.reshape(1, -1), n_neighbors=3, return_distance=False)[0]\n",
    "    test_features.append(transformed[indices])\n",
    "test_features = np.array(test_features)\n",
    "test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.tensor(test_features).float().to(device)\n",
    "index = 18\n",
    "noise = torch.randn(test_input.shape[0], noise_dim, device=device)\n",
    "output = G(noise, test_input).detach().cpu().numpy()\n",
    "output_shaped = pca.inverse_transform(output).reshape(len(output), x.shape[-2], x.shape[-1])\n",
    "output_shaped.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Assuming you already have 'output_shaped', 'x', and 'y' as inputs\n",
    "output_shaped[output_shaped < 0] = 0\n",
    "\n",
    "attempt = 1\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, axes_list = plt.subplots(len(output_shaped), 3, figsize=(10, 100))\n",
    "\n",
    "# Gaussian filter parameters (adjust these for your case)\n",
    "sigma = 1.2  # Standard deviation for the Gaussian filter\n",
    "\n",
    "for i in range(len(output_shaped)):\n",
    "    axes = axes_list[i].flatten()\n",
    "\n",
    "    # Apply Gaussian filter to spread out pixel values\n",
    "    output_shaped_spread = gaussian_filter(output_shaped[i], sigma=sigma)\n",
    "\n",
    "    axes[0].imshow(gaussian_filter(x[i][0], sigma=sigma))\n",
    "    axes[1].imshow(gaussian_filter(y[i][0], sigma=sigma))\n",
    "    axes[2].imshow(output_shaped_spread)\n",
    "\n",
    "    if i == 0:\n",
    "        axes[0].set_title('Input Itinerary', fontweight='bold')\n",
    "        axes[1].set_title('Expected Itinerary', fontweight='bold')\n",
    "        axes[2].set_title('Generated Itinerary (Spread)', fontweight='bold')\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "# Save the figure with spread-out images\n",
    "plt.savefig(f'../fig/gan_output/{i}_{attempt}_spread.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Assuming you already have 'output_shaped', 'x', and 'y' as inputs\n",
    "output_shaped[output_shaped < 0] = 0\n",
    "\n",
    "attempt = 1\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# Adjust figure size for a more balanced layout\n",
    "fig, axes_list = plt.subplots(len(output_shaped), 3, figsize=(15, len(output_shaped) * 5))\n",
    "\n",
    "# Gaussian filter parameters (adjust these for your case)\n",
    "sigma = 1.2  # Standard deviation for the Gaussian filter\n",
    "\n",
    "for i in range(len(output_shaped)):\n",
    "    axes = axes_list[i].flatten()\n",
    "\n",
    "    # Apply Gaussian filter to spread out pixel values\n",
    "    output_shaped_spread = gaussian_filter(output_shaped[i], sigma=sigma)\n",
    "    \n",
    "    # Apply Gaussian filter to input and expected images as well\n",
    "    x_filtered = gaussian_filter(x[i][0], sigma=sigma)\n",
    "    y_filtered = gaussian_filter(y[i][0] + x[i][0], sigma=sigma)\n",
    "\n",
    "    # Display images with appropriate colormap\n",
    "    im0 = axes[0].imshow(x_filtered, cmap='viridis')\n",
    "    im1 = axes[1].imshow(y_filtered, cmap='viridis')\n",
    "    im2 = axes[2].imshow(output_shaped_spread, cmap='viridis')\n",
    "\n",
    "    # Titles with better readability\n",
    "    if i == 0:\n",
    "        axes[0].set_title('Input Itinerary', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_title('Expected Itinerary', fontsize=14, fontweight='bold')\n",
    "        axes[2].set_title('Generated Itinerary (Spread)', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Remove ticks for cleaner look\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    # Add colorbars for better understanding of intensity\n",
    "    plt.colorbar(im0, ax=axes[0], shrink=0.6)\n",
    "    plt.colorbar(im1, ax=axes[1], shrink=0.6)\n",
    "    plt.colorbar(im2, ax=axes[2], shrink=0.6)\n",
    "\n",
    "# Adjust the layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure with high resolution (dpi = 300 for high-quality output)\n",
    "plt.savefig(f'../fig/gan_output/{i}_{attempt}_spread.png', dpi=300)\n",
    "\n",
    "# Show plot (optional)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_shaped[output_shaped < 0] = 0\n",
    "attempt = 1\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "fig, axes_list = plt.subplots(len(output_shaped), 3, figsize=(10, 100))\n",
    "for i in range(len(output_shaped)):\n",
    "    axes = axes_list[i].flatten()\n",
    "\n",
    "    axes[0].imshow(x[i][0])\n",
    "    axes[1].imshow(y[i][0])\n",
    "    axes[2].imshow(output_shaped[i])\n",
    "    if i == 0:\n",
    "        axes[0].set_title('input itinerary', fontweight='bold')\n",
    "        axes[1].set_title('expected itinerary', fontweight='bold')\n",
    "        axes[2].set_title('generated itinerary', fontweight='bold')\n",
    "    for ax in axes:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.savefig(f'../fig/gan_output/{i}_{attempt}.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
