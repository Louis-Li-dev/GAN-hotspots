{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tqdm\n",
    "# %pip install python-dotenv\n",
    "# %pip install torch==2.4.0+cu118\n",
    "# %pip install scikit_learn==1.2.2\n",
    "# %pip install ipython\n",
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install tabulate\n",
    "# %pip install scipy\n",
    "# %pip install git+https://github.com/Louis-Li-dev/ML_tool_kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.join(os.getcwd(), '..')\n",
    "if parent_dir not in sys.path: sys.path.append(parent_dir)\n",
    "from utility.data_utils import *\n",
    "from utility.visuals import *\n",
    "from dotenv import load_dotenv\n",
    "from model.CNN import ConditionalSegmentationVAE\n",
    "from mkit.torch_support.tensor_utils import xy_to_tensordataset\n",
    "from torch import nn\n",
    "from IPython.display import clear_output\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "load_dotenv()\n",
    "DATA_DIR = os.getenv(\"DATA_DIR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_DIR): raise FileNotFoundError(\"Make sure the data directory is correctly placed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset size: 238\n",
      "dataset size with duplicates removed: 172\n"
     ]
    }
   ],
   "source": [
    "files = get_files(DATA_DIR)\n",
    "\n",
    "return_list = []\n",
    "file = files[0]\n",
    "city_name = file.split('\\\\')[-1].split('.csv')[0].split('_')[0]\n",
    "\n",
    "path_name = process_and_transform_data(file, resolution=.5, overwrite=True)\n",
    "with open(path_name, 'rb') as f:\n",
    "    result_dict = pickle.load(f)\n",
    "labels = result_dict['labels']\n",
    "encoder = result_dict['encoder']\n",
    "MAX_LEN = result_dict['max length']\n",
    "file_name = result_dict['file name']\n",
    "WIDTH = result_dict['width']\n",
    "HEIGHT = result_dict['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, label in enumerate(labels):\n",
    "#     plt.imshow(labels[idx])\n",
    "#     plt.savefig(f'../fig/{idx}_{file_name}.png')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x y splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "unique_labels = [u for u in labels if np.array(np.where(u != 0)).T.shape[0] > 1]\n",
    "padded_labels = []\n",
    "for label in unique_labels:\n",
    "    unique_vals = np.unique(label)[1:]\n",
    "    new_vals = []\n",
    "    count = 0\n",
    "    for val in unique_vals:    \n",
    "        dummy_vals = np.zeros(label.shape)\n",
    "        dummy_vals[np.where(label == val)] = 1\n",
    "        new_vals.append(dummy_vals)\n",
    "        count += 1\n",
    "    for i in range(count, MAX_LEN):\n",
    "        dummy_vals = np.zeros(label.shape)\n",
    "        new_vals.append(dummy_vals)\n",
    "    new_vals = np.array(new_vals)\n",
    "    padded_labels.append(new_vals)\n",
    "train_labels, test_labels = train_test_split(padded_labels, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, start_dim, n_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(input_dim, start_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(start_dim),\n",
    "            nn.Mish(),\n",
    "        ]\n",
    "        \n",
    "        in_channels = start_dim\n",
    "        for _ in range(n_layers):\n",
    "            out_channels = in_channels * 2\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1))\n",
    "            if _ != n_layers - 1:\n",
    "                layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.Mish())\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, start_dim, n_layers, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        in_channels = start_dim * (2 ** n_layers)\n",
    "        layers = []\n",
    "        \n",
    "        for _ in range(n_layers):\n",
    "            out_channels = in_channels // 2\n",
    "            layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.Mish())\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        layers.append(nn.ConvTranspose2d(in_channels, output_dim, kernel_size=3, stride=2, padding=1, output_padding=1))\n",
    "        layers.append(nn.Sigmoid())  # Ensure output is between 0 and 1 for images\n",
    "        \n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, start_dim, n_layers, output_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, start_dim, n_layers)\n",
    "        self.decoder = Decoder(start_dim, n_layers, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "def generate(input_dim, start_dim, n_layers, output_dim, device=\"cpu\", output_type=\"autoencoder\"):\n",
    "    \"\"\"\n",
    "    Creates an encoder, decoder, or autoencoder model based on user input.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Number of input channels (e.g., 3 for RGB).\n",
    "        start_dim (int): The first convolution layer's channel count.\n",
    "        n_layers (int): Number of encoder layers (each doubling start_dim).\n",
    "        output_dim (int): The number of output channels.\n",
    "        device (str): 'cpu' or 'cuda' (GPU).\n",
    "        output_type (str): 'encoder', 'decoder', or 'autoencoder'.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch model on the selected device.\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    if output_type == \"encoder\":\n",
    "        model = Encoder(input_dim, start_dim, n_layers)\n",
    "    elif output_type == \"decoder\":\n",
    "        model = Decoder(start_dim, n_layers, output_dim)\n",
    "    elif output_type == \"autoencoder\":\n",
    "        model = Autoencoder(input_dim, start_dim, n_layers, output_dim)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid output_type. Choose from 'encoder', 'decoder', or 'autoencoder'.\")\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, start_dim, n_layers, latent_dim, img_width, img_height):\n",
    "        super(Encoder, self).__init__()\n",
    "        layers = [\n",
    "            nn.Conv2d(input_dim, start_dim, kernel_size=3, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(start_dim),\n",
    "            nn.Mish(),\n",
    "        ]\n",
    "        \n",
    "        in_channels = start_dim\n",
    "        for _ in range(n_layers):\n",
    "            out_channels = in_channels * 2\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "            if _ != n_layers - 1:\n",
    "                layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.Mish())\n",
    "            in_channels = out_channels\n",
    "\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        # Compute the final spatial size after convolutions\n",
    "        self.final_width = img_width\n",
    "        self.final_height = img_height \n",
    "        self.final_channels = in_channels\n",
    "\n",
    "        # Fully Connected Layers for Latent Space\n",
    "        self.fc_mu = nn.Linear(self.final_channels * self.final_width * self.final_height, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.final_channels * self.final_width * self.final_height, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, start_dim, n_layers, output_dim, latent_dim, img_width, img_height):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Compute the final spatial size\n",
    "        self.final_width = img_width\n",
    "        self.final_height = img_height\n",
    "        self.final_channels = start_dim * (2 ** n_layers)\n",
    "\n",
    "        # Fully Connected Layer to reshape back to feature map\n",
    "        self.fc = nn.Linear(latent_dim, self.final_channels * self.final_width * self.final_height)\n",
    "\n",
    "        layers = []\n",
    "        in_channels = self.final_channels\n",
    "        for _ in range(n_layers):\n",
    "            out_channels = in_channels // 2\n",
    "            layers.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "            layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.Mish())\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        layers.append(nn.ConvTranspose2d(in_channels, output_dim, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.decoder = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(x.size(0), self.final_channels, self.final_width, self.final_height)  # Reshape to feature map\n",
    "        return self.decoder(x)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, start_dim, n_layers, output_dim, latent_dim, img_width, img_height):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, start_dim, n_layers, latent_dim, img_width, img_height)\n",
    "        self.decoder = Decoder(start_dim, n_layers, output_dim, latent_dim, img_width, img_height)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Reparameterization trick: sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)  # Convert log variance to std\n",
    "        eps = torch.randn_like(std)  # Sample from standard normal\n",
    "        return mu + eps * std  # Reparameterized latent vector\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mu, logvar\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    Compute the VAE loss function:\n",
    "    Loss = Reconstruction Loss + KL Divergence\n",
    "    \"\"\"\n",
    "    recon_loss = nn.functional.l1_loss(recon_x, x, reduction='sum')  # BCE Loss\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())  # KL Divergence Loss\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "def generate(input_dim, start_dim, n_layers, output_dim, latent_dim, img_width, img_height, device=\"cpu\", output_type=\"vae\"):\n",
    "    \"\"\"\n",
    "    Creates an encoder, decoder, or VAE model based on user input.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Number of input channels (e.g., 3 for RGB).\n",
    "        start_dim (int): The first convolution layer's channel count.\n",
    "        n_layers (int): Number of encoder layers (each doubling start_dim).\n",
    "        output_dim (int): The number of output channels.\n",
    "        latent_dim (int): Size of the latent representation.\n",
    "        img_width (int): Input image width.\n",
    "        img_height (int): Input image height.\n",
    "        device (str): 'cpu' or 'cuda' (GPU).\n",
    "        output_type (str): 'encoder', 'decoder', or 'vae'.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch model on the selected device.\n",
    "    \"\"\"\n",
    "    device = torch.device(device)\n",
    "\n",
    "    if output_type == \"encoder\":\n",
    "        model = Encoder(input_dim, start_dim, n_layers, latent_dim, img_width, img_height)\n",
    "    elif output_type == \"decoder\":\n",
    "        model = Decoder(start_dim, n_layers, output_dim, latent_dim, img_width, img_height)\n",
    "    elif output_type == \"vae\":\n",
    "        model = VAE(input_dim, start_dim, n_layers, output_dim, latent_dim, img_width, img_height)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid output_type. Choose from 'encoder', 'decoder', or 'vae'.\")\n",
    "    return model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ss348\\anaconda3\\Lib\\site-packages\\mkit\\torch_support\\tensor_utils.py:438: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  return torch.tensor(arr)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader, val_loader = xy_to_tensordataset(\n",
    "    train_labels, train_labels,\n",
    "    return_loader=True, \n",
    "    batch_size=8,\n",
    "    input_dtype=torch.float32,\n",
    "    output_dtype=torch.float32,\n",
    "    val_ratio=.15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/15, Loss: 110989.9453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:02<04:17,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] -> Train Loss: 11029.3370, Val Loss: 6662.4688\n",
      "Batch 0/15, Loss: 53010.921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:04<03:12,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100] -> Train Loss: 5029.0870, Val Loss: 3401.2288\n",
      "Batch 0/15, Loss: 27934.47265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:05<02:50,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100] -> Train Loss: 2568.8621, Val Loss: 2034.5694\n",
      "Batch 0/15, Loss: 16451.583984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:07<02:39,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100] -> Train Loss: 1677.0883, Val Loss: 1452.1664\n",
      "Batch 0/15, Loss: 12316.263671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:08<02:33,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100] -> Train Loss: 1354.3142, Val Loss: 1285.6215\n",
      "Batch 0/15, Loss: 10542.470703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:10<02:28,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100] -> Train Loss: 1233.1052, Val Loss: 1284.0447\n",
      "Batch 0/15, Loss: 10232.572265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:11<02:24,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100] -> Train Loss: 1162.4549, Val Loss: 1247.9496\n",
      "Batch 0/15, Loss: 9466.384765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:13<02:21,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100] -> Train Loss: 1139.4319, Val Loss: 1149.7653\n",
      "Batch 0/15, Loss: 9461.3173828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:14<02:19,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100] -> Train Loss: 1102.4043, Val Loss: 1093.2441\n",
      "Batch 0/15, Loss: 8905.826171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:16<02:17,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100] -> Train Loss: 1104.2976, Val Loss: 1110.5934\n",
      "Batch 0/15, Loss: 8704.041015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:17<02:15,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100] -> Train Loss: 1040.4995, Val Loss: 1043.2520\n",
      "Batch 0/15, Loss: 8479.0361328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:19<02:13,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100] -> Train Loss: 990.3621, Val Loss: 1031.1952\n",
      "Batch 0/15, Loss: 8389.9365234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:20<02:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100] -> Train Loss: 1014.2032, Val Loss: 1017.6205\n",
      "Batch 0/15, Loss: 8278.4150390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:22<02:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100] -> Train Loss: 974.3655, Val Loss: 1047.9387\n",
      "Batch 0/15, Loss: 7847.0224609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:23<02:08,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100] -> Train Loss: 974.5167, Val Loss: 979.5726\n",
      "Batch 0/15, Loss: 8123.89208984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:25<02:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100] -> Train Loss: 931.7137, Val Loss: 991.8883\n",
      "Batch 0/15, Loss: 8275.189453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:26<02:05,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100] -> Train Loss: 937.8498, Val Loss: 952.9932\n",
      "Batch 0/15, Loss: 7652.419921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:28<02:04,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100] -> Train Loss: 911.5971, Val Loss: 915.9164\n",
      "Batch 0/15, Loss: 7222.15234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:29<02:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100] -> Train Loss: 884.2695, Val Loss: 906.5962\n",
      "Batch 0/15, Loss: 7296.37109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:31<02:01,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100] -> Train Loss: 881.8227, Val Loss: 883.8383\n",
      "Batch 0/15, Loss: 7182.7001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:32<01:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] -> Train Loss: 874.7723, Val Loss: 887.3431\n",
      "Batch 0/15, Loss: 7863.7490234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:34<01:58,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100] -> Train Loss: 867.7261, Val Loss: 857.1394\n",
      "Batch 0/15, Loss: 6991.5712890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:35<01:56,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100] -> Train Loss: 844.2210, Val Loss: 842.6861\n",
      "Batch 0/15, Loss: 6654.7841796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:37<01:55,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100] -> Train Loss: 841.9506, Val Loss: 886.1443\n",
      "Batch 0/15, Loss: 6913.7900390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:38<01:53,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100] -> Train Loss: 832.6941, Val Loss: 829.7659\n",
      "Batch 0/15, Loss: 6725.314453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:40<01:52,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100] -> Train Loss: 818.3607, Val Loss: 818.5828\n",
      "Batch 0/15, Loss: 6837.27685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:42<01:51,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100] -> Train Loss: 810.3386, Val Loss: 812.9352\n",
      "Batch 0/15, Loss: 6655.3115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:43<01:49,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100] -> Train Loss: 801.8000, Val Loss: 817.3744\n",
      "Batch 0/15, Loss: 6532.37890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:45<01:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100] -> Train Loss: 792.0423, Val Loss: 801.4392\n",
      "Batch 0/15, Loss: 6537.9541015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:46<01:46,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100] -> Train Loss: 792.3305, Val Loss: 822.4996\n",
      "Batch 0/15, Loss: 6474.98828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:48<01:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100] -> Train Loss: 804.0775, Val Loss: 784.7706\n",
      "Batch 0/15, Loss: 6366.21484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:49<01:43,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100] -> Train Loss: 774.2946, Val Loss: 783.5898\n",
      "Batch 0/15, Loss: 6281.7841796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:51<01:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100] -> Train Loss: 771.1225, Val Loss: 801.0930\n",
      "Batch 0/15, Loss: 6372.3662109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:52<01:40,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100] -> Train Loss: 778.1918, Val Loss: 766.9318\n",
      "Batch 0/15, Loss: 6320.060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:54<01:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100] -> Train Loss: 758.8704, Val Loss: 768.0302\n",
      "Batch 0/15, Loss: 6460.6689453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:55<01:37,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100] -> Train Loss: 758.4916, Val Loss: 773.3020\n",
      "Batch 0/15, Loss: 5984.5166015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:57<01:36,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100] -> Train Loss: 746.2582, Val Loss: 769.2116\n",
      "Batch 0/15, Loss: 6399.66650390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:58<01:34,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100] -> Train Loss: 745.2767, Val Loss: 737.6899\n",
      "Batch 0/15, Loss: 5978.1171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [01:00<01:32,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100] -> Train Loss: 742.1978, Val Loss: 768.2829\n",
      "Batch 0/15, Loss: 6597.98828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:01<01:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100] -> Train Loss: 745.3474, Val Loss: 740.9006\n",
      "Batch 0/15, Loss: 5972.794921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [01:03<01:29,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100] -> Train Loss: 731.3381, Val Loss: 725.5362\n",
      "Batch 0/15, Loss: 5926.90087890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [01:04<01:28,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100] -> Train Loss: 718.6130, Val Loss: 729.7798\n",
      "Batch 0/15, Loss: 5861.83056640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [01:06<01:26,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100] -> Train Loss: 716.8400, Val Loss: 733.2270\n",
      "Batch 0/15, Loss: 6035.837890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [01:07<01:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100] -> Train Loss: 719.9351, Val Loss: 727.6836\n",
      "Batch 0/15, Loss: 5850.47998046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [01:09<01:23,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100] -> Train Loss: 716.9881, Val Loss: 712.6067\n",
      "Batch 0/15, Loss: 5882.2900390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [01:10<01:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100] -> Train Loss: 706.5972, Val Loss: 722.7470\n",
      "Batch 0/15, Loss: 5683.5517578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [01:12<01:20,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100] -> Train Loss: 704.6133, Val Loss: 702.1877\n",
      "Batch 0/15, Loss: 5654.861328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [01:13<01:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100] -> Train Loss: 701.2289, Val Loss: 729.6012\n",
      "Batch 0/15, Loss: 5790.814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [01:15<01:17,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100] -> Train Loss: 702.7997, Val Loss: 685.8254\n",
      "Batch 0/15, Loss: 5644.15625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [01:16<01:15,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100] -> Train Loss: 689.6384, Val Loss: 691.9190\n",
      "Batch 0/15, Loss: 5449.5478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [01:18<01:14,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100] -> Train Loss: 679.8870, Val Loss: 693.5401\n",
      "Batch 0/15, Loss: 5667.615234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [01:20<01:12,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100] -> Train Loss: 687.1397, Val Loss: 681.9216\n",
      "Batch 0/15, Loss: 5560.12255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [01:21<01:11,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100] -> Train Loss: 682.6427, Val Loss: 686.0410\n",
      "Batch 0/15, Loss: 5548.7744140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [01:23<01:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100] -> Train Loss: 674.9927, Val Loss: 687.1125\n",
      "Batch 0/15, Loss: 5651.15185546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [01:24<01:08,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100] -> Train Loss: 676.3023, Val Loss: 691.3077\n",
      "Batch 0/15, Loss: 5505.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [01:26<01:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100] -> Train Loss: 674.4822, Val Loss: 685.3078\n",
      "Batch 0/15, Loss: 5482.7802734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [01:27<01:05,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100] -> Train Loss: 672.7338, Val Loss: 680.6870\n",
      "Batch 0/15, Loss: 5368.83203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [01:29<01:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100] -> Train Loss: 660.4764, Val Loss: 671.2964\n",
      "Batch 0/15, Loss: 5375.8369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [01:30<01:02,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100] -> Train Loss: 661.8573, Val Loss: 674.2105\n",
      "Batch 0/15, Loss: 5329.478515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [01:32<01:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100] -> Train Loss: 660.0636, Val Loss: 681.1411\n",
      "Batch 0/15, Loss: 5484.7255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [01:33<00:59,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100] -> Train Loss: 662.3227, Val Loss: 681.8728\n",
      "Batch 0/15, Loss: 5526.080078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [01:35<00:57,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100] -> Train Loss: 664.4994, Val Loss: 673.5237\n",
      "Batch 0/15, Loss: 5594.60595703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [01:36<00:56,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100] -> Train Loss: 650.8854, Val Loss: 663.3314\n",
      "Batch 0/15, Loss: 5329.87841796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [01:38<00:54,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100] -> Train Loss: 647.2824, Val Loss: 649.8457\n",
      "Batch 0/15, Loss: 5321.62548828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [01:39<00:53,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100] -> Train Loss: 646.9975, Val Loss: 663.9457\n",
      "Batch 0/15, Loss: 5353.41943359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [01:41<00:51,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100] -> Train Loss: 642.9118, Val Loss: 639.8220\n",
      "Batch 0/15, Loss: 5237.845703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [01:42<00:50,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100] -> Train Loss: 636.1783, Val Loss: 631.4540\n",
      "Batch 0/15, Loss: 5309.0048828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [01:44<00:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100] -> Train Loss: 634.7351, Val Loss: 637.0422\n",
      "Batch 0/15, Loss: 5138.798828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [01:45<00:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100] -> Train Loss: 630.0595, Val Loss: 632.6694\n",
      "Batch 0/15, Loss: 5192.47216796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [01:47<00:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100] -> Train Loss: 631.7931, Val Loss: 639.1463\n",
      "Batch 0/15, Loss: 5119.060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [01:48<00:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100] -> Train Loss: 626.3941, Val Loss: 641.1310\n",
      "Batch 0/15, Loss: 5184.8291015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [01:50<00:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100] -> Train Loss: 629.5217, Val Loss: 634.9527\n",
      "Batch 0/15, Loss: 5139.31396484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [01:51<00:41,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100] -> Train Loss: 628.8567, Val Loss: 633.0335\n",
      "Batch 0/15, Loss: 5129.451171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [01:53<00:39,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100] -> Train Loss: 620.2337, Val Loss: 635.0375\n",
      "Batch 0/15, Loss: 5024.7255859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [01:55<00:38,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100] -> Train Loss: 621.4891, Val Loss: 631.4376\n",
      "Batch 0/15, Loss: 4964.2060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [01:56<00:36,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100] -> Train Loss: 613.9300, Val Loss: 620.4281\n",
      "Batch 0/15, Loss: 5107.8681640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [01:58<00:35,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100] -> Train Loss: 615.8252, Val Loss: 617.9318\n",
      "Batch 0/15, Loss: 4913.1708984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [01:59<00:33,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100] -> Train Loss: 611.1281, Val Loss: 618.3478\n",
      "Batch 0/15, Loss: 4881.41357421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [02:01<00:31,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100] -> Train Loss: 605.0773, Val Loss: 625.7442\n",
      "Batch 0/15, Loss: 5020.3984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [02:02<00:30,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100] -> Train Loss: 608.4173, Val Loss: 615.3275\n",
      "Batch 0/15, Loss: 4983.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [02:04<00:28,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100] -> Train Loss: 607.3688, Val Loss: 613.4560\n",
      "Batch 0/15, Loss: 4932.29638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [02:05<00:27,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100] -> Train Loss: 600.5799, Val Loss: 609.2226\n",
      "Batch 0/15, Loss: 4922.68359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [02:07<00:25,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100] -> Train Loss: 599.8084, Val Loss: 606.0621\n",
      "Batch 0/15, Loss: 4870.79443359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [02:08<00:24,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100] -> Train Loss: 599.1909, Val Loss: 601.3280\n",
      "Batch 0/15, Loss: 4870.37548828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [02:10<00:22,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100] -> Train Loss: 594.0340, Val Loss: 610.9258\n",
      "Batch 0/15, Loss: 4886.98193359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [02:11<00:21,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100] -> Train Loss: 598.0028, Val Loss: 608.2222\n",
      "Batch 0/15, Loss: 4878.2734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [02:13<00:19,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100] -> Train Loss: 591.2324, Val Loss: 600.4648\n",
      "Batch 0/15, Loss: 4810.63232421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [02:14<00:18,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100] -> Train Loss: 589.4168, Val Loss: 590.8696\n",
      "Batch 0/15, Loss: 4808.5302734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [02:16<00:16,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100] -> Train Loss: 590.2892, Val Loss: 594.7473\n",
      "Batch 0/15, Loss: 4795.4638671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [02:17<00:15,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100] -> Train Loss: 587.7745, Val Loss: 592.1956\n",
      "Batch 0/15, Loss: 4892.58447265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [02:19<00:13,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100] -> Train Loss: 581.9381, Val Loss: 586.6184\n",
      "Batch 0/15, Loss: 4701.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [02:20<00:12,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100] -> Train Loss: 581.1246, Val Loss: 580.1523\n",
      "Batch 0/15, Loss: 4713.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [02:22<00:10,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100] -> Train Loss: 579.4215, Val Loss: 587.4908\n",
      "Batch 0/15, Loss: 4768.67431640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [02:23<00:09,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100] -> Train Loss: 580.6338, Val Loss: 582.8176\n",
      "Batch 0/15, Loss: 4614.5166015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [02:25<00:07,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100] -> Train Loss: 578.3966, Val Loss: 587.8333\n",
      "Batch 0/15, Loss: 4645.93603515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [02:26<00:06,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100] -> Train Loss: 575.8713, Val Loss: 578.1358\n",
      "Batch 0/15, Loss: 4672.876953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [02:28<00:04,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100] -> Train Loss: 571.2236, Val Loss: 574.8613\n",
      "Batch 0/15, Loss: 4689.6083984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [02:29<00:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100] -> Train Loss: 573.6072, Val Loss: 578.1544\n",
      "Batch 0/15, Loss: 4678.8603515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [02:31<00:01,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100] -> Train Loss: 569.1872, Val Loss: 574.5159\n",
      "Batch 0/15, Loss: 4580.98095703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:33<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100] -> Train Loss: 570.1748, Val Loss: 579.0814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_vae(model, train_loader, optimizer, device=\"cuda\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):  # Assume data is (images, labels)\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = model(x)\n",
    "\n",
    "        loss = vae_loss(recon_x, x, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "def validate_vae(model, val_loader, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, _ in val_loader:\n",
    "            x = x.to(device)\n",
    "            recon_x, mu, logvar = model(x)\n",
    "\n",
    "            loss = vae_loss(recon_x, x, mu, logvar)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "    return avg_loss\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "vae = generate(input_dim=MAX_LEN, start_dim=32, n_layers=2, output_dim=MAX_LEN, latent_dim=128, img_width=WIDTH, img_height=HEIGHT, device=device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss = train_vae(vae, loader, optimizer, device)\n",
    "    val_loss = validate_vae(vae, val_loader, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] -> Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vae(torch.tensor(train_labels, device=torch.device('cuda')).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_labels[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00530585  0.00633608 -0.00638314 ...  0.00518536 -0.00131768\n",
      "   0.00907136]\n",
      " [ 0.00221615  0.00256875  0.00782794 ... -0.00094632 -0.01038616\n",
      "  -0.01108993]\n",
      " [ 0.00177421 -0.00223001  0.01357553 ... -0.01358774 -0.00376088\n",
      "   0.00159471]\n",
      " ...\n",
      " [ 0.00295518 -0.01272563 -0.00072261 ...  0.00638906 -0.00952257\n",
      "  -0.01091492]\n",
      " [ 0.00035631 -0.00960466  0.00403384 ...  0.00229139  0.00248394\n",
      "  -0.00643252]\n",
      " [ 0.00429464  0.02110469 -0.00134287 ... -0.00969957 -0.00710573\n",
      "   0.00029883]]\n",
      "[[-0.00072498  0.01165395 -0.01203468 ... -0.00026623 -0.00352166\n",
      "  -0.00156105]\n",
      " [-0.01218804  0.00872565  0.0049587  ...  0.01449727  0.00385981\n",
      "  -0.01701123]\n",
      " [-0.00077201  0.0016752   0.0153474  ... -0.00931995 -0.00846378\n",
      "   0.00990718]\n",
      " ...\n",
      " [ 0.01136915 -0.01241709 -0.00327679 ... -0.00210019 -0.0082287\n",
      "  -0.02145121]\n",
      " [-0.00609333 -0.00463604 -0.00419081 ... -0.01975758  0.00138683\n",
      "  -0.00873357]\n",
      " [ 0.00126963  0.01228953 -0.01093542 ...  0.004294   -0.01047825\n",
      "  -0.00312002]]\n",
      "[[-0.00735565  0.0083959  -0.01472246 ... -0.00069241 -0.0101297\n",
      "   0.00606436]\n",
      " [ 0.00365422  0.00161363  0.01260159 ...  0.01236475 -0.00362068\n",
      "  -0.0180601 ]\n",
      " [ 0.00097022 -0.00448119  0.02102194 ... -0.00574272  0.00110225\n",
      "   0.0074544 ]\n",
      " ...\n",
      " [ 0.00386343 -0.01170687 -0.00513681 ... -0.00027724  0.0027738\n",
      "  -0.0133699 ]\n",
      " [-0.00385291 -0.00729861  0.00679418 ... -0.01456884  0.00364063\n",
      "  -0.0020625 ]\n",
      " [-0.00045101  0.00806721 -0.0115075  ...  0.01281423 -0.00583831\n",
      "  -0.0020191 ]]\n",
      "[[ 0.00475445  0.00150296 -0.00260192 ... -0.00093169 -0.00186614\n",
      "  -0.00039878]\n",
      " [-0.00808377  0.00376175  0.01567871 ...  0.00912716 -0.0045008\n",
      "  -0.01573638]\n",
      " [ 0.01310217 -0.00372272  0.00277577 ...  0.00702227 -0.00167355\n",
      "   0.00454608]\n",
      " ...\n",
      " [ 0.0143783  -0.02270126 -0.00090154 ...  0.01384214  0.00914242\n",
      "  -0.00399468]\n",
      " [ 0.00134868 -0.00841936  0.02264468 ... -0.00516128  0.00260561\n",
      "  -0.01037848]\n",
      " [ 0.00527096  0.01427699 -0.00853787 ...  0.00944574 -0.00520186\n",
      "  -0.00736401]]\n",
      "[[ 0.00787022  0.0025979  -0.00244167 ... -0.01690391 -0.00745599\n",
      "   0.00243562]\n",
      " [ 0.00379183  0.00202957 -0.00318042 ... -0.00620645  0.01110837\n",
      "  -0.00209097]\n",
      " [ 0.00208125 -0.01425725  0.00468127 ... -0.00166331 -0.00807665\n",
      "   0.01764049]\n",
      " ...\n",
      " [-0.00040659  0.00804556 -0.01334366 ...  0.01076082 -0.00435536\n",
      "  -0.00689448]\n",
      " [-0.00199837 -0.00773295 -0.00411267 ... -0.00617383 -0.00731868\n",
      "  -0.01170639]\n",
      " [ 0.01212733  0.01193739 -0.01881742 ... -0.00331558 -0.00386314\n",
      "  -0.00032632]]\n",
      "[[ 0.00360329  0.01115178 -0.01821422 ...  0.00293023 -0.00352124\n",
      "  -0.00545184]\n",
      " [-0.00243402 -0.00227785  0.01837913 ...  0.00450107 -0.00687625\n",
      "  -0.0144166 ]\n",
      " [ 0.02484613  0.0072794   0.01566619 ... -0.00145508  0.0039669\n",
      "   0.01457547]\n",
      " ...\n",
      " [ 0.00912068 -0.01547056 -0.00836816 ... -0.00277373  0.01209434\n",
      "  -0.01341883]\n",
      " [ 0.00299478  0.0004589  -0.01083382 ... -0.01527139  0.01005856\n",
      "   0.00535195]\n",
      " [ 0.0018741   0.01260225 -0.0037512  ...  0.00176238 -0.01275992\n",
      "  -0.00592283]]\n",
      "[[-0.0007403   0.00062287 -0.00414162 ... -0.00737354 -0.00595918\n",
      "   0.003194  ]\n",
      " [ 0.00158866  0.00418466 -0.00319121 ...  0.00190834  0.00179655\n",
      "  -0.0191784 ]\n",
      " [ 0.00552448 -0.00603237  0.01413352 ... -0.00685219 -0.01060198\n",
      "   0.016718  ]\n",
      " ...\n",
      " [ 0.00197513 -0.0111815  -0.01463076 ...  0.00439791  0.00275036\n",
      "  -0.00416059]\n",
      " [-0.01753623 -0.01214393 -0.00633887 ... -0.00670605  0.01693117\n",
      "  -0.00014398]\n",
      " [ 0.00119994  0.01315629  0.00727606 ...  0.00232788 -0.00687062\n",
      "  -0.00981891]]\n",
      "[[-0.00264516  0.01336608 -0.010663   ...  0.0071049  -0.01457478\n",
      "   0.003181  ]\n",
      " [ 0.00363267  0.00964985  0.00953274 ...  0.00807229 -0.00506052\n",
      "  -0.02191559]\n",
      " [ 0.01051716  0.00905109  0.00858316 ... -0.01307719  0.00540506\n",
      "   0.00518363]\n",
      " ...\n",
      " [ 0.0143123  -0.01419703  0.00086508 ...  0.00597504  0.01081531\n",
      "  -0.00520998]\n",
      " [-0.00916579 -0.01469939  0.00806967 ...  0.00508944  0.0029341\n",
      "  -0.01061155]\n",
      " [ 0.00808532  0.0101675  -0.00902639 ...  0.00659805 -0.00472392\n",
      "  -0.00248372]]\n",
      "[[ 0.00055659  0.02233511 -0.00975245 ... -0.00980771 -0.00634992\n",
      "   0.00397739]\n",
      " [-0.00520552  0.00715404 -0.00060926 ...  0.01095255  0.00242714\n",
      "  -0.02619935]\n",
      " [ 0.00499829  0.01321507  0.00845311 ... -0.00432941 -0.00174619\n",
      "   0.00285549]\n",
      " ...\n",
      " [ 0.01170028 -0.01463562 -0.00921323 ...  0.00532851 -0.00816631\n",
      "  -0.01044285]\n",
      " [-0.00875831 -0.00868749 -0.00261813 ... -0.01140728  0.00782616\n",
      "  -0.0055094 ]\n",
      " [ 0.01140334  0.01030996 -0.02559078 ...  0.00257678 -0.01067592\n",
      "  -0.00073936]]\n",
      "[[ 0.00273258  0.00281813 -0.00228237 ... -0.00244888 -0.01127749\n",
      "   0.00986615]\n",
      " [ 0.00174016  0.01058858 -0.00276851 ...  0.00049805 -0.00100588\n",
      "  -0.00478869]\n",
      " [ 0.00131883  0.00712607  0.00926075 ... -0.00513014  0.00198508\n",
      "   0.01273833]\n",
      " ...\n",
      " [ 0.00045774 -0.0110796  -0.00365421 ...  0.02139393  0.01557391\n",
      "  -0.01635955]\n",
      " [-0.0060452  -0.00429734 -0.00529892 ... -0.0042532  -0.00181193\n",
      "  -0.01990151]\n",
      " [-0.00203348  0.00696286  0.00325408 ...  0.00039253  0.00538232\n",
      "  -0.0009487 ]]\n",
      "[[ 0.00259144  0.0028492  -0.0076456  ... -0.00461155 -0.00606863\n",
      "   0.00098484]\n",
      " [-0.00595012  0.01192038  0.0083322  ...  0.00487541  0.00943227\n",
      "  -0.01031765]\n",
      " [ 0.01142675 -0.00261014  0.01226313 ... -0.00494417  0.00238946\n",
      "   0.01287638]\n",
      " ...\n",
      " [ 0.02290248 -0.01277009 -0.00037017 ... -0.00025251  0.01085997\n",
      "  -0.01044362]\n",
      " [-0.01415189 -0.0152758  -0.00221362 ...  0.00445797  0.0050584\n",
      "   0.0005345 ]\n",
      " [ 0.00918592  0.00275142 -0.00412522 ...  0.00837444 -0.004501\n",
      "  -0.00399706]]\n",
      "[[-1.1939639e-03  4.3660654e-03 -1.3892793e-02 ...  7.4164039e-03\n",
      "  -2.6310049e-02  2.8119152e-03]\n",
      " [ 3.0687815e-03 -1.1171439e-02  1.6675599e-02 ... -9.8679308e-04\n",
      "   1.5895940e-02 -1.5920423e-02]\n",
      " [ 6.7022284e-03  1.3797646e-03  2.6601829e-02 ... -6.6342885e-03\n",
      "  -1.5393579e-03  1.5532150e-02]\n",
      " ...\n",
      " [ 4.9112802e-03 -7.8725899e-03 -1.1726462e-02 ...  6.6337641e-04\n",
      "   6.0045039e-03  6.9788657e-05]\n",
      " [-5.4918015e-03 -6.1514014e-03 -2.3980523e-03 ... -2.9096240e-03\n",
      "   9.8302728e-03 -1.8020431e-03]\n",
      " [ 7.7198958e-03  1.4417431e-02 -5.3827846e-03 ... -9.7437510e-03\n",
      "   4.6774279e-04 -2.2829045e-04]]\n",
      "[[-0.00051367  0.01216403 -0.01270556 ...  0.01582126 -0.01547399\n",
      "  -0.00076447]\n",
      " [-0.01098514  0.01279374  0.00389799 ...  0.00091068  0.0026514\n",
      "  -0.00884805]\n",
      " [ 0.03148888  0.02025417  0.01334245 ... -0.00345814  0.00516605\n",
      "   0.00679115]\n",
      " ...\n",
      " [-0.00255545 -0.03055828  0.00678996 ...  0.00692753  0.00466927\n",
      "  -0.01081937]\n",
      " [-0.00525577 -0.00557657 -0.00693914 ... -0.01162683 -0.00367818\n",
      "  -0.00266826]\n",
      " [ 0.01100475  0.00361984 -0.00557502 ... -0.00340746 -0.0003283\n",
      "  -0.00215638]]\n",
      "[[-5.48595563e-05  4.76385932e-03 -8.87524430e-03 ...  6.09001145e-05\n",
      "  -1.74313132e-03 -3.00980452e-03]\n",
      " [-1.68300513e-03  1.06136939e-02  5.63909765e-03 ...  4.66243085e-03\n",
      "  -2.92819832e-03 -1.38512487e-02]\n",
      " [ 1.76635459e-02  1.24192797e-04  1.04527539e-02 ... -2.15737596e-02\n",
      "   1.24574294e-02  1.19241318e-02]\n",
      " ...\n",
      " [ 7.59444293e-03 -1.73993632e-02 -7.80203287e-03 ... -1.48155633e-03\n",
      "   2.70297285e-03  2.62487587e-03]\n",
      " [-4.46253456e-04 -1.18866498e-02  3.61489411e-03 ...  3.47786304e-03\n",
      "   7.30294641e-03 -1.19136358e-02]\n",
      " [ 1.08368164e-02  3.17209121e-03 -3.15087382e-03 ...  1.15484288e-02\n",
      "  -1.56138744e-03  1.19505795e-02]]\n",
      "[[ 0.00506449  0.00810194 -0.00467994 ... -0.00224688 -0.01635914\n",
      "   0.0090481 ]\n",
      " [-0.00261801  0.00104918 -0.00204077 ...  0.02105055 -0.00239041\n",
      "  -0.00870206]\n",
      " [ 0.01126607 -0.01193746  0.00881917 ... -0.00928316 -0.01215996\n",
      "   0.0201578 ]\n",
      " ...\n",
      " [ 0.01025686 -0.02269883 -0.00247981 ...  0.01183931 -0.00316913\n",
      "  -0.00669543]\n",
      " [-0.01685094 -0.00944092 -0.00127467 ... -0.01148983  0.01230872\n",
      "  -0.00574506]\n",
      " [-0.0044305   0.00808857 -0.00230263 ...  0.00584392 -0.0035181\n",
      "  -0.00726885]]\n",
      "[[ 0.00359768  0.01105423 -0.0163817  ... -0.0026939  -0.01434422\n",
      "  -0.00238203]\n",
      " [-0.00020894  0.00131922 -0.00011138 ... -0.00621604  0.0079494\n",
      "  -0.00152422]\n",
      " [ 0.01001701  0.00646687  0.00807617 ...  0.00052944 -0.00671686\n",
      "   0.00704027]\n",
      " ...\n",
      " [-0.00093732 -0.02656292 -0.00937953 ...  0.00340781 -0.00100886\n",
      "  -0.01852127]\n",
      " [-0.01098878 -0.00214013  0.01532411 ... -0.00644343  0.01179428\n",
      "  -0.00091071]\n",
      " [ 0.00485247  0.00176033 -0.00776897 ...  0.00353952  0.00340773\n",
      "   0.00122612]]\n",
      "[[ 0.00440162  0.0099029  -0.02433594 ... -0.01230296 -0.01147191\n",
      "   0.003984  ]\n",
      " [-0.00598771  0.00234358  0.01214286 ...  0.00822393  0.00483546\n",
      "  -0.01496282]\n",
      " [ 0.01783944 -0.00108533  0.01430801 ... -0.00327442 -0.0156591\n",
      "   0.02719764]\n",
      " ...\n",
      " [ 0.01037014 -0.01546007 -0.00927826 ...  0.00121275  0.00731916\n",
      "  -0.02060155]\n",
      " [-0.0110132  -0.02128341 -0.00990608 ...  0.00082243  0.00377334\n",
      "   0.00090324]\n",
      " [ 0.01154149  0.01177658 -0.01402325 ... -0.01835192 -0.01018593\n",
      "  -0.00146893]]\n",
      "[[ 4.4676429e-03 -1.0048607e-03 -1.0397636e-02 ...  2.0389922e-02\n",
      "  -3.2418314e-04 -1.3741339e-03]\n",
      " [ 5.6870645e-03  3.8471064e-03 -8.8629965e-04 ...  3.0202037e-03\n",
      "   2.4468359e-04 -1.4002987e-02]\n",
      " [ 1.7840229e-02  6.3739484e-03  2.3319818e-02 ...  1.8368578e-03\n",
      "   2.8523123e-03  8.8466620e-03]\n",
      " ...\n",
      " [ 8.5497564e-03 -8.0756778e-03  5.5083996e-03 ...  4.6756631e-03\n",
      "  -5.1575247e-04 -9.3883658e-03]\n",
      " [-7.1079517e-03  9.8596578e-03 -3.5145069e-03 ... -4.6342099e-03\n",
      "   1.1962420e-02 -1.9898945e-03]\n",
      " [ 5.9114015e-03  4.2021489e-03  1.4768904e-03 ... -8.4855594e-05\n",
      "   1.0438012e-03  2.7665785e-03]]\n",
      "[[-0.00157339  0.00869685 -0.01932504 ...  0.00723884 -0.01547167\n",
      "  -0.00464717]\n",
      " [-0.00607758 -0.00168991  0.00607131 ...  0.00984234  0.0054002\n",
      "  -0.02600691]\n",
      " [ 0.02283321  0.00352115  0.02267293 ... -0.00252805  0.00101621\n",
      "   0.01521648]\n",
      " ...\n",
      " [ 0.01090992 -0.01894241 -0.00062569 ... -0.00162383  0.00772164\n",
      "  -0.01224022]\n",
      " [ 0.00103275  0.00368176 -0.00541882 ...  0.00024893  0.00509315\n",
      "   0.00557262]\n",
      " [ 0.00043913  0.00759409 -0.01059111 ... -0.00353132  0.00036995\n",
      "  -0.00347616]]\n",
      "[[ 0.00265471 -0.00342993 -0.00624808 ... -0.0071295  -0.00822892\n",
      "   0.00756863]\n",
      " [ 0.00122901 -0.00364808  0.00241817 ...  0.01268374 -0.00187782\n",
      "  -0.00859242]\n",
      " [ 0.00641532  0.01295871  0.0169485  ...  0.00281539 -0.00580896\n",
      "   0.01854862]\n",
      " ...\n",
      " [ 0.01078983 -0.01347631 -0.01195421 ...  0.01387713  0.00542805\n",
      "  -0.00687965]\n",
      " [ 0.00327406 -0.01035043  0.00409887 ... -0.00424738  0.01236556\n",
      "  -0.0020132 ]\n",
      " [-0.00430415  0.00168543 -0.00836424 ... -0.00602321 -0.00120415\n",
      "  -0.00220114]]\n",
      "[[ 1.9975659e-04  1.7203771e-02 -9.2947716e-03 ...  3.0139154e-03\n",
      "  -1.3546208e-03 -8.2088355e-04]\n",
      " [ 2.3512607e-03  4.7179302e-03  2.9987656e-05 ... -2.2301162e-03\n",
      "  -2.6353830e-03 -2.0067329e-03]\n",
      " [ 1.4642014e-02 -2.0385467e-02  1.2481994e-02 ... -6.8789804e-03\n",
      "   2.1117320e-03  1.6625486e-02]\n",
      " ...\n",
      " [ 5.8894968e-03 -2.4013363e-02 -7.0054764e-03 ...  8.9383489e-03\n",
      "   4.2700833e-03 -7.6068724e-03]\n",
      " [-2.3309523e-03 -4.0835971e-03  3.3751940e-03 ...  3.9482033e-03\n",
      "   5.3366190e-03  3.9924448e-03]\n",
      " [ 2.1523898e-03  1.2768171e-02  6.6636270e-03 ... -1.9448856e-03\n",
      "  -1.6162880e-03 -3.5453485e-03]]\n",
      "[[ 0.00164943  0.00921907 -0.011992   ... -0.00143784 -0.01213537\n",
      "  -0.00436328]\n",
      " [ 0.00642379  0.01217721  0.01639254 ...  0.00968747  0.00469252\n",
      "  -0.01606198]\n",
      " [ 0.0084954  -0.00167327  0.0054144  ... -0.00884955 -0.00122783\n",
      "   0.00309323]\n",
      " ...\n",
      " [ 0.01129433 -0.02119521 -0.00227531 ...  0.0087835   0.00666913\n",
      "  -0.00485357]\n",
      " [-0.01286202 -0.01104694 -0.01029038 ... -0.00661641  0.00762147\n",
      "  -0.00649265]\n",
      " [ 0.01171491 -0.000302    0.00578477 ...  0.00310028 -0.00477336\n",
      "   0.00166114]]\n",
      "[[-0.00718141  0.00198955 -0.01724892 ... -0.00405207 -0.01537338\n",
      "   0.0040047 ]\n",
      " [-0.00168222 -0.0084684   0.0066613  ... -0.00132559 -0.00817999\n",
      "  -0.01032824]\n",
      " [ 0.02166452  0.00061405  0.01512522 ...  0.0047045  -0.00773547\n",
      "   0.01323882]\n",
      " ...\n",
      " [ 0.00234983 -0.01761318 -0.00914302 ...  0.00181899 -0.00527188\n",
      "  -0.00455072]\n",
      " [-0.00999891 -0.00926604  0.00721685 ...  0.00397567  0.01208306\n",
      "  -0.00887732]\n",
      " [ 0.00839562  0.01199015 -0.01501561 ... -0.00517444 -0.00920071\n",
      "   0.00236081]]\n",
      "[[ 0.00411742 -0.00641766 -0.01542958 ...  0.00740986 -0.01289631\n",
      "  -0.0009933 ]\n",
      " [-0.00152842 -0.00359817  0.01323882 ...  0.00269169  0.00647525\n",
      "  -0.01863887]\n",
      " [ 0.01085243  0.01046953  0.01830301 ... -0.01461186 -0.00789232\n",
      "   0.00725867]\n",
      " ...\n",
      " [ 0.01471463 -0.00025707 -0.01144805 ... -0.00720092  0.00289638\n",
      "  -0.01078273]\n",
      " [-0.00177012 -0.02253797  0.0190058  ... -0.00640128  0.01217992\n",
      "  -0.00711979]\n",
      " [ 0.01648793  0.00787108 -0.00952435 ...  0.00189472 -0.00389531\n",
      "  -0.00596034]]\n",
      "[[ 0.0080838   0.00616589  0.00319556 ...  0.00279754 -0.00666881\n",
      "  -0.00249168]\n",
      " [ 0.00656482 -0.00215847  0.0193389  ...  0.01936483 -0.00603672\n",
      "  -0.01280799]\n",
      " [ 0.01587497  0.00779999  0.01178298 ... -0.01537018  0.00514458\n",
      "   0.01491792]\n",
      " ...\n",
      " [ 0.0189799  -0.01189599 -0.00641187 ...  0.00532655  0.00625265\n",
      "   0.00960604]\n",
      " [-0.00804625  0.00353027  0.01090201 ...  0.00091886  0.00585972\n",
      "  -0.00660444]\n",
      " [ 0.00012881  0.00451527 -0.01159357 ...  0.01877934  0.00232282\n",
      "  -0.00111219]]\n",
      "[[ 4.5392876e-03  1.6389675e-02 -1.8345736e-02 ...  1.6700514e-02\n",
      "  -1.6645208e-02 -6.1341561e-05]\n",
      " [ 1.2746667e-03  8.1626317e-03 -1.6090209e-03 ...  6.7352420e-03\n",
      "   6.0692867e-03 -1.3181129e-02]\n",
      " [ 1.5042937e-02  9.0076989e-03  2.2725143e-02 ... -1.1225515e-02\n",
      "   2.0551300e-03  8.9167617e-05]\n",
      " ...\n",
      " [ 3.7606275e-03 -2.0666219e-02  4.4497019e-03 ...  6.5518981e-03\n",
      "   8.2419431e-03 -2.2755913e-02]\n",
      " [-5.5281604e-03 -1.8674666e-03  9.8977452e-03 ...  8.6731371e-04\n",
      "   2.6394194e-03 -2.0907605e-03]\n",
      " [ 7.1075177e-03  1.1148027e-02 -1.4409312e-02 ...  4.4012358e-03\n",
      "  -2.7946830e-03 -6.4172456e-03]]\n",
      "[[ 2.9341197e-03 -3.2435181e-03 -8.7089175e-03 ... -1.2405599e-03\n",
      "  -5.9471810e-03 -6.1334157e-03]\n",
      " [ 4.0279543e-03  2.0981409e-02  2.7605869e-02 ...  2.6173657e-03\n",
      "   4.6860268e-03 -1.6429462e-05]\n",
      " [ 1.3243808e-02  3.2061990e-04  2.0640768e-02 ... -6.5828050e-03\n",
      "   6.8330234e-03  9.3167415e-03]\n",
      " ...\n",
      " [ 1.1244244e-02 -4.8452551e-03 -2.0793313e-03 ... -2.1448964e-03\n",
      "   2.5713062e-03  1.8688357e-03]\n",
      " [-7.5850124e-03 -1.8078171e-02 -4.9121911e-03 ... -2.1168375e-03\n",
      "   5.6076264e-03 -4.0439749e-03]\n",
      " [ 1.8172510e-02  2.4879389e-02 -6.8529630e-03 ... -2.9032165e-03\n",
      "  -4.2693345e-03 -4.1453959e-03]]\n",
      "[[ 3.8111424e-03 -5.5334801e-03  5.6951707e-03 ...  1.7944342e-03\n",
      "  -9.7082937e-03  4.5585549e-03]\n",
      " [-4.2979950e-03  1.3250119e-02 -8.7712053e-04 ...  8.6588329e-03\n",
      "  -7.8573171e-04 -8.7179923e-03]\n",
      " [ 1.2338086e-02  5.2095419e-03  1.9825049e-02 ... -1.1308827e-02\n",
      "  -1.4173845e-03  9.5932325e-03]\n",
      " ...\n",
      " [ 7.5618085e-04 -9.5591331e-03 -6.1146254e-03 ...  2.8568869e-03\n",
      "  -2.5399961e-05  5.9156772e-04]\n",
      " [-1.1749634e-02 -1.3960891e-02 -5.2685970e-03 ... -1.9758577e-03\n",
      "   4.1329330e-03  1.9902205e-03]\n",
      " [-1.7505232e-04  3.0511385e-03 -4.7443444e-03 ...  5.7168892e-03\n",
      "   2.2028936e-03 -4.2543272e-03]]\n",
      "[[-1.0925942e-02  8.9520765e-03 -1.8839888e-02 ... -3.8542785e-05\n",
      "  -9.5552886e-03 -5.2486742e-03]\n",
      " [-1.2778425e-02  3.6128080e-03  1.2894980e-02 ...  2.1732813e-03\n",
      "   3.2290658e-03 -1.7124452e-02]\n",
      " [-3.1130174e-03 -5.2177841e-03  5.2829152e-03 ... -2.3424275e-02\n",
      "  -9.1576213e-03  1.4032221e-02]\n",
      " ...\n",
      " [ 2.9445447e-02 -1.1263811e-02 -5.7313675e-03 ... -1.7249817e-03\n",
      "   7.1547842e-03 -2.9969001e-03]\n",
      " [-7.9964185e-03 -1.0701799e-02  3.5275435e-03 ...  7.3936647e-03\n",
      "   5.8478927e-03 -6.8690488e-03]\n",
      " [ 6.6593206e-03  1.7004974e-02 -1.0021799e-02 ...  1.0601645e-03\n",
      "  -4.4504087e-04  2.3212759e-03]]\n",
      "[[-0.00167907  0.00324992 -0.00656372 ...  0.00245564 -0.01312275\n",
      "  -0.00326798]\n",
      " [ 0.00342704  0.00156892  0.01062534 ...  0.00374495  0.00702402\n",
      "  -0.01181402]\n",
      " [ 0.00664389  0.00427145  0.0081313  ...  0.00221581 -0.00233997\n",
      "   0.01268442]\n",
      " ...\n",
      " [ 0.00486121  0.00322977 -0.00292202 ...  0.00367812  0.00015966\n",
      "  -0.01215168]\n",
      " [ 0.00119198 -0.01388543  0.00580945 ... -0.0053924   0.00429843\n",
      "  -0.00660512]\n",
      " [ 0.01220361  0.01194058 -0.01108608 ...  0.00398607 -0.00576618\n",
      "   0.00027998]]\n",
      "[[ 0.00060991  0.01209472 -0.00269791 ... -0.00221403 -0.0103027\n",
      "   0.00229729]\n",
      " [-0.00355796  0.00980494  0.0011403  ...  0.00451688 -0.00559738\n",
      "  -0.00923254]\n",
      " [ 0.00165752  0.01027322  0.0166688  ... -0.0119249  -0.00670768\n",
      "   0.0238225 ]\n",
      " ...\n",
      " [ 0.00822089 -0.00260759 -0.02207121 ...  0.01291946 -0.00011494\n",
      "  -0.00784231]\n",
      " [-0.00336083 -0.00792619 -0.00803382 ... -0.0108209  -0.00412526\n",
      "  -0.00544724]\n",
      " [ 0.002402    0.00221697 -0.01171272 ...  0.00060714 -0.00305568\n",
      "   0.00122877]]\n",
      "[[-0.00311361 -0.00261983 -0.00688332 ...  0.00838674 -0.01236355\n",
      "   0.00131941]\n",
      " [-0.00748027  0.00948241  0.01391528 ...  0.00396085  0.0055469\n",
      "  -0.01422509]\n",
      " [ 0.00050526  0.00041402  0.02806971 ... -0.01274667 -0.00030173\n",
      "   0.00604814]\n",
      " ...\n",
      " [ 0.01334093 -0.00493018  0.00164286 ... -0.00025543  0.00877742\n",
      "  -0.01366281]\n",
      " [ 0.00188548 -0.00634583  0.01589414 ...  0.00238027  0.01030528\n",
      "  -0.00147013]\n",
      " [ 0.01205868  0.00861239 -0.00128644 ...  0.0066912  -0.0082202\n",
      "  -0.0042158 ]]\n",
      "[[-6.4832652e-03  5.2752746e-03 -2.0630294e-03 ...  6.8259751e-03\n",
      "   3.8451618e-03  1.9892817e-03]\n",
      " [ 7.0416089e-04  1.3512517e-02  4.4660335e-03 ... -5.6890631e-03\n",
      "   1.0477400e-02 -2.6011700e-03]\n",
      " [ 6.5683387e-05 -3.2783384e-03  3.2395698e-02 ... -1.5647478e-02\n",
      "   4.3368628e-03  9.5385220e-04]\n",
      " ...\n",
      " [ 6.9415038e-03 -1.4184513e-02 -2.0289563e-02 ... -6.6601867e-03\n",
      "  -1.6190372e-02 -6.4158374e-03]\n",
      " [-8.7407911e-03 -6.5075392e-03  1.5024003e-04 ...  1.5132194e-03\n",
      "   3.2378649e-03 -1.0812708e-02]\n",
      " [ 1.0170287e-02  1.7071879e-03 -1.0792259e-04 ...  6.4275330e-03\n",
      "  -1.7559407e-03 -2.3074159e-03]]\n",
      "[[-2.4292106e-03 -4.4049686e-03 -5.6138271e-03 ...  7.6236865e-03\n",
      "  -1.0157750e-02  1.0434947e-02]\n",
      " [-7.3098578e-05  1.1492958e-03 -5.9491778e-03 ... -1.9679600e-03\n",
      "   8.8938987e-03  9.4807707e-05]\n",
      " [-3.7331367e-03  8.2277721e-03  1.9734956e-02 ... -2.2746855e-03\n",
      "   3.0988362e-04  7.5480407e-03]\n",
      " ...\n",
      " [-2.9109353e-03 -1.2978115e-02 -1.8775485e-02 ...  8.2703596e-03\n",
      "  -8.0912942e-03 -6.9905454e-03]\n",
      " [-4.2850757e-03 -4.0427381e-03 -7.1524316e-03 ... -1.4070415e-02\n",
      "   4.0021604e-03 -6.6043595e-03]\n",
      " [ 3.9820438e-03 -3.0194158e-03  2.1144664e-03 ...  3.3075130e-03\n",
      "   1.4745304e-03 -6.8533951e-03]]\n",
      "[[ 0.00286054  0.00208727 -0.00517156 ...  0.00580816 -0.00499427\n",
      "  -0.00163851]\n",
      " [ 0.0036645  -0.00080011  0.00969013 ... -0.0032891   0.00169792\n",
      "  -0.01255845]\n",
      " [ 0.00952642  0.00137693  0.02142433 ...  0.00080565 -0.01650216\n",
      "   0.00167852]\n",
      " ...\n",
      " [-0.00949105 -0.02195366 -0.01798185 ...  0.00621585 -0.00151844\n",
      "  -0.01301146]\n",
      " [ 0.00520854 -0.00400727  0.01618805 ... -0.00788092  0.01016124\n",
      "  -0.01003412]\n",
      " [ 0.01055554  0.01404899 -0.0042801  ... -0.00168644 -0.00216865\n",
      "  -0.00459221]]\n",
      "[[-0.0050711   0.00798644 -0.00328954 ...  0.0084042  -0.01864145\n",
      "  -0.0021399 ]\n",
      " [ 0.00269247 -0.0148098   0.01308165 ...  0.02121042  0.00686268\n",
      "  -0.00759644]\n",
      " [ 0.0020865   0.02166832  0.02009249 ...  0.00115967  0.0040111\n",
      "   0.00154725]\n",
      " ...\n",
      " [ 0.01691628  0.00289593 -0.01023271 ... -0.00226649  0.01180012\n",
      "   0.00260625]\n",
      " [ 0.00577264  0.00294203  0.00914008 ... -0.01056358  0.0117571\n",
      "   0.00274101]\n",
      " [ 0.00988773  0.00956582 -0.01113045 ... -0.00298338 -0.00560859\n",
      "   0.0037351 ]]\n",
      "[[ 0.00560149  0.00749966 -0.01445928 ... -0.00280478 -0.01260448\n",
      "   0.00219995]\n",
      " [ 0.00382119  0.0008911   0.00311147 ... -0.00010976  0.01094606\n",
      "  -0.00735972]\n",
      " [ 0.00163776 -0.00106486  0.0102822  ... -0.00132511  0.00041325\n",
      "   0.01435691]\n",
      " ...\n",
      " [-0.00259983 -0.01856557 -0.00642809 ...  0.00996373  0.00782355\n",
      "  -0.00756184]\n",
      " [-0.00288121 -0.00513452  0.00133137 ...  0.00537784  0.00717746\n",
      "   0.00573546]\n",
      " [ 0.00257554  0.01341946 -0.01059411 ... -0.00689707  0.0015589\n",
      "   0.00558612]]\n",
      "[[-0.00580379 -0.0091618  -0.01108926 ... -0.00480279 -0.00369749\n",
      "   0.00687066]\n",
      " [-0.005726    0.00598049 -0.00096011 ...  0.00265457  0.00869934\n",
      "  -0.01191429]\n",
      " [ 0.00651028 -0.00433236  0.01030285 ...  0.00358351  0.00160111\n",
      "  -0.0009952 ]\n",
      " ...\n",
      " [ 0.01101444 -0.01672266  0.00097302 ... -0.00176057 -0.00501929\n",
      "  -0.00866497]\n",
      " [-0.00122454 -0.01079615  0.00647954 ... -0.02143008  0.00120651\n",
      "  -0.00231974]\n",
      " [ 0.00152173  0.00691869 -0.01768342 ...  0.00664238 -0.00266869\n",
      "  -0.00325302]]\n",
      "[[-0.0043968   0.01129732 -0.01103108 ...  0.00057868 -0.02028695\n",
      "   0.00602319]\n",
      " [-0.00120583 -0.00140521 -0.00557891 ...  0.00295459 -0.00514265\n",
      "  -0.01198235]\n",
      " [ 0.00700534  0.00729564  0.00443379 ... -0.01510058 -0.0102546\n",
      "   0.01856283]\n",
      " ...\n",
      " [ 0.01085465 -0.00692033 -0.01043048 ... -0.00076046 -0.00476515\n",
      "  -0.00891996]\n",
      " [-0.00860081 -0.02062019  0.00294837 ... -0.00038     0.00037012\n",
      "  -0.0090254 ]\n",
      " [ 0.01358779  0.02026223 -0.00642593 ...  0.00683863  0.00468671\n",
      "  -0.00175089]]\n",
      "[[ 0.00118977  0.00756768 -0.00490751 ...  0.00568725 -0.01330241\n",
      "   0.00350724]\n",
      " [ 0.00192126 -0.00131713 -0.0112798  ...  0.02002803 -0.00506098\n",
      "  -0.01951314]\n",
      " [-0.00144534  0.00220851  0.00963274 ... -0.01312021 -0.00173783\n",
      "   0.0060742 ]\n",
      " ...\n",
      " [ 0.01032949 -0.00460302  0.00167874 ...  0.007686    0.00470631\n",
      "  -0.00570994]\n",
      " [ 0.00640777 -0.00637081  0.00258204 ... -0.01524375 -0.00621178\n",
      "  -0.01203743]\n",
      " [ 0.00479524  0.00859516 -0.00265315 ...  0.01774751  0.00246088\n",
      "  -0.00717261]]\n",
      "[[ 5.15454169e-03  6.32268097e-03 -1.30661670e-03 ...  2.53763702e-03\n",
      "  -5.42128179e-03  6.31827768e-03]\n",
      " [ 6.78083953e-03  5.77038061e-03  6.45268615e-03 ...  1.55187910e-02\n",
      "  -7.87434075e-03 -1.35168368e-02]\n",
      " [ 1.20835965e-02  7.21401535e-04  1.13637811e-02 ... -1.42400805e-03\n",
      "   1.17615517e-03  1.18592074e-02]\n",
      " ...\n",
      " [ 8.52527376e-03 -1.76113918e-02 -5.39197866e-03 ...  1.96338668e-02\n",
      "   1.10975420e-02  6.64209947e-05]\n",
      " [-8.75566248e-03 -2.92637292e-03  6.43875357e-03 ... -4.15334944e-03\n",
      "   8.97487160e-03 -8.15419201e-03]\n",
      " [-4.09022812e-03  1.03715425e-02 -1.01754898e-02 ... -6.78573642e-03\n",
      "  -1.07034715e-02 -1.30825676e-04]]\n",
      "[[ 0.00520155 -0.00100476 -0.00454819 ...  0.00242097 -0.0050733\n",
      "   0.01048934]\n",
      " [-0.00192913  0.0030919  -0.00788552 ...  0.00920535 -0.0137186\n",
      "  -0.00701154]\n",
      " [ 0.00569091 -0.00825723  0.0113906  ... -0.01037551 -0.00660863\n",
      "   0.0124516 ]\n",
      " ...\n",
      " [ 0.00387034 -0.01263111 -0.00750288 ...  0.01510111 -0.00328963\n",
      "  -0.0072121 ]\n",
      " [-0.00482801 -0.00702214 -0.01582352 ...  0.00037681  0.00426901\n",
      "  -0.01921333]\n",
      " [ 0.00153068 -0.00192066  0.00179734 ... -0.00441261  0.0012966\n",
      "   0.00976377]]\n",
      "[[-0.00119988 -0.0035144  -0.01536565 ...  0.00944058 -0.01300785\n",
      "   0.0071831 ]\n",
      " [-0.00032578  0.00219549 -0.00054836 ... -0.00086271  0.0112605\n",
      "  -0.00803895]\n",
      " [ 0.01121215 -0.00106653  0.02000955 ...  0.00121403 -0.00979891\n",
      "   0.01163144]\n",
      " ...\n",
      " [-0.00420483 -0.01907612 -0.02292433 ...  0.00194112 -0.00501738\n",
      "  -0.0120909 ]\n",
      " [-0.00822578 -0.01371922  0.00377016 ... -0.01000685  0.00954481\n",
      "  -0.0119838 ]\n",
      " [ 0.00441458 -0.00551926 -0.00988629 ... -0.0092773  -0.00360098\n",
      "  -0.00313306]]\n",
      "[[ 0.00264392  0.00135558 -0.00936964 ...  0.01216566 -0.01466839\n",
      "  -0.00176083]\n",
      " [-0.0048626  -0.00222635  0.01498011 ... -0.01461717 -0.0010823\n",
      "  -0.0044592 ]\n",
      " [ 0.01320914 -0.00744911  0.03383819 ... -0.00048854  0.00712567\n",
      "   0.00848495]\n",
      " ...\n",
      " [ 0.01383335 -0.01140278 -0.02240571 ...  0.000482    0.01384012\n",
      "  -0.01315454]\n",
      " [-0.00495889 -0.01407745 -0.00132307 ...  0.01011825  0.01182005\n",
      "  -0.01041629]\n",
      " [ 0.00825051  0.02349228 -0.01257525 ... -0.00653675  0.0021218\n",
      "   0.00632549]]\n",
      "[[-0.00095853 -0.00010077 -0.01435968 ...  0.01455963 -0.02527658\n",
      "   0.00141262]\n",
      " [ 0.00686934  0.00044076  0.01496879 ... -0.00088     0.00201071\n",
      "  -0.01065696]\n",
      " [ 0.01228037 -0.0040405   0.01776073 ... -0.00069981  0.00526583\n",
      "   0.00039934]\n",
      " ...\n",
      " [ 0.00032436 -0.02212342  0.0103055  ...  0.0099763   0.00415415\n",
      "  -0.00514688]\n",
      " [-0.01348619  0.00017214 -0.00134257 ... -0.00049143  0.01866087\n",
      "   0.00096571]\n",
      " [ 0.00668337  0.00783811 -0.01193205 ... -0.00197498  0.00368742\n",
      "   0.00551215]]\n",
      "[[-0.00310405  0.00033192 -0.0012193  ... -0.01451128 -0.00657894\n",
      "   0.00201362]\n",
      " [-0.00457765 -0.00036939  0.01937979 ...  0.0020544   0.00629108\n",
      "  -0.01358602]\n",
      " [-0.00301427  0.00826273  0.01000438 ... -0.01601998 -0.00427351\n",
      "   0.01108456]\n",
      " ...\n",
      " [-0.00848194 -0.00307814  0.00925884 ...  0.00638161  0.01126892\n",
      "  -0.01145884]\n",
      " [-0.00866222 -0.01400267 -0.00823226 ... -0.00120271  0.0203617\n",
      "  -0.00028516]\n",
      " [ 0.01494484  0.0241875  -0.01668615 ...  0.00066572  0.00478968\n",
      "  -0.01331215]]\n",
      "[[ 0.00228887  0.00865709 -0.02110311 ...  0.00092918 -0.01804099\n",
      "   0.00118049]\n",
      " [ 0.00367779 -0.00120036  0.01336235 ...  0.01481437  0.00795624\n",
      "  -0.00559016]\n",
      " [ 0.00722203  0.00798408  0.02174494 ... -0.01430253 -0.00278896\n",
      "   0.01656338]\n",
      " ...\n",
      " [ 0.01365647 -0.00329461 -0.01354035 ... -0.00991037 -0.00943429\n",
      "  -0.00751948]\n",
      " [-0.00300744 -0.01545399  0.00082671 ...  0.00726824  0.00277925\n",
      "  -0.00900015]\n",
      " [ 0.00859912  0.0163046  -0.01143616 ... -0.006524    0.0005465\n",
      "  -0.0028357 ]]\n",
      "[[-1.7899508e-03  2.1052942e-02  2.1329289e-03 ... -6.1767641e-04\n",
      "  -9.3752081e-03 -2.9928330e-04]\n",
      " [ 6.2471693e-03  6.8651913e-03  1.8774174e-02 ...  1.4586947e-02\n",
      "  -6.3023055e-03 -2.0414079e-03]\n",
      " [ 2.2523798e-02  3.2119220e-03  1.2070931e-02 ... -1.0169753e-02\n",
      "  -5.4824213e-03  1.2868836e-02]\n",
      " ...\n",
      " [ 6.5021580e-03 -1.7247088e-02 -1.6858183e-02 ...  6.5517789e-03\n",
      "  -5.3667659e-03 -1.3211974e-02]\n",
      " [-1.4708393e-02 -1.8753046e-03 -1.6998388e-02 ...  1.7244136e-03\n",
      "   3.0378168e-03 -5.6330422e-03]\n",
      " [ 3.1357631e-06  1.5633300e-02 -4.8908228e-03 ...  3.0804640e-03\n",
      "   7.7326251e-03 -7.2512263e-03]]\n",
      "[[-0.00264042  0.00233041 -0.00384509 ...  0.01124305 -0.01772746\n",
      "  -0.0030837 ]\n",
      " [-0.01273205 -0.01342614  0.02522678 ...  0.00913138 -0.01762814\n",
      "  -0.01700478]\n",
      " [ 0.00561225  0.01979954  0.01509906 ...  0.00909717  0.01077481\n",
      "   0.00569882]\n",
      " ...\n",
      " [ 0.01901219 -0.01415234 -0.00394669 ...  0.00738463  0.00243973\n",
      "  -0.00807842]\n",
      " [ 0.00371519 -0.00263473 -0.0007607  ...  0.00456411  0.01154909\n",
      "  -0.0014192 ]\n",
      " [ 0.00296212  0.01701113  0.0027842  ... -0.004037   -0.00232237\n",
      "   0.00910837]]\n",
      "[[-0.00034461  0.01246156 -0.00870078 ... -0.0041803  -0.00496605\n",
      "  -0.00785651]\n",
      " [-0.00326655  0.004882    0.00096013 ... -0.01108994 -0.00019316\n",
      "  -0.00860863]\n",
      " [ 0.0042403  -0.00578158  0.01219148 ...  0.01134757 -0.00670295\n",
      "   0.01408785]\n",
      " ...\n",
      " [-0.0069611  -0.01267783 -0.01107814 ...  0.00561956  0.00406159\n",
      "  -0.00644925]\n",
      " [-0.00237132 -0.00292885  0.00599611 ... -0.00808296  0.00630545\n",
      "  -0.0068209 ]\n",
      " [ 0.00410067  0.01063201 -0.00918678 ... -0.0068759  -0.0074003\n",
      "   0.0009838 ]]\n",
      "[[ 0.00048678  0.01085685 -0.00818726 ...  0.01249276 -0.01419843\n",
      "   0.00593311]\n",
      " [ 0.00308559 -0.00977098  0.0013976  ...  0.00856819 -0.00135696\n",
      "  -0.01681883]\n",
      " [ 0.00649706 -0.00707211  0.02013011 ...  0.00482774  0.00049335\n",
      "   0.01120391]\n",
      " ...\n",
      " [-0.00347156 -0.02246981 -0.01226636 ...  0.00308559  0.00512624\n",
      "  -0.02089479]\n",
      " [-0.01030123 -0.00304266  0.00287896 ... -0.00271025  0.00466905\n",
      "  -0.00976704]\n",
      " [ 0.0050417   0.00538546 -0.01147332 ...  0.0022306   0.00341299\n",
      "  -0.00575434]]\n",
      "[[-7.3649827e-04 -1.5817666e-03 -9.7486908e-03 ...  4.7100848e-03\n",
      "  -1.5928455e-02 -9.4430987e-04]\n",
      " [ 1.4635092e-03  9.4091361e-03  8.8955527e-03 ... -1.9221092e-03\n",
      "   6.0007935e-03 -1.4411905e-02]\n",
      " [ 5.6936732e-03 -2.8903419e-03 -3.3593709e-03 ...  5.2711731e-03\n",
      "  -4.3411488e-03  1.9044653e-02]\n",
      " ...\n",
      " [-1.2582475e-03 -1.7769448e-02 -4.0466422e-03 ...  8.9590913e-03\n",
      "   2.8058207e-03 -7.3056156e-03]\n",
      " [-4.1309679e-03 -1.2506479e-03  1.2433997e-02 ...  3.6558574e-03\n",
      "   4.7966605e-03 -1.6560532e-02]\n",
      " [ 1.0858721e-02  4.1232025e-03 -1.0395982e-02 ... -2.7568731e-04\n",
      "   9.1076829e-05  9.1109378e-03]]\n",
      "[[ 0.00580589  0.00497883 -0.0159538  ... -0.00240611 -0.00081695\n",
      "   0.00882085]\n",
      " [-0.00134     0.01370707  0.00320244 ... -0.00045139  0.00589202\n",
      "  -0.01642663]\n",
      " [ 0.01095981  0.00322501  0.00836176 ...  0.00070982 -0.00205799\n",
      "   0.02369516]\n",
      " ...\n",
      " [ 0.00928814 -0.00323116 -0.01463219 ... -0.00464621 -0.00213345\n",
      "  -0.00588789]\n",
      " [-0.01019194 -0.01368954 -0.0054098  ... -0.00094577  0.01370972\n",
      "   0.00677209]\n",
      " [ 0.00143579  0.01503431 -0.00489221 ...  0.00048391 -0.00671486\n",
      "  -0.00051878]]\n",
      "[[-0.00195468  0.00090989 -0.02572488 ... -0.0013308  -0.01859623\n",
      "  -0.00199302]\n",
      " [-0.00462934 -0.01021227 -0.00606624 ...  0.00744634  0.00250625\n",
      "  -0.00253259]\n",
      " [ 0.00197934 -0.0020019   0.02096284 ... -0.00552189 -0.00196284\n",
      "   0.01891576]\n",
      " ...\n",
      " [-0.00318223 -0.01857465 -0.01664617 ...  0.01024256  0.00019803\n",
      "   0.00330844]\n",
      " [-0.00414834 -0.00512048  0.00075027 ... -0.01380495  0.01613259\n",
      "  -0.01117567]\n",
      " [ 0.00653791  0.01365534 -0.02217313 ... -0.0074527  -0.00654057\n",
      "   0.00229672]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred_np = pred[0].cpu().detach().numpy()\n",
    "count = 0\n",
    "for ele in pred_np:\n",
    "    print(ele[0])\n",
    "    plt.imshow(ele[0], vmax=1, vmin=0)\n",
    "    count += 1\n",
    "    plt.savefig('../fig/model_figs/' + str(count) + '.png')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(np\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mmask\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m))\u001b[38;5;241m.\u001b[39mT[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxxx.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      3\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(count\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mask' is not defined"
     ]
    }
   ],
   "source": [
    "count = np.array(np.where(mask.cpu().detach().numpy() != False)).T[:, 0]\n",
    "with open('xxx.txt', 'w') as f:\n",
    "    f.write(str(count.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_labels[15][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = pred\n",
    "masked_pred = pred * mask\n",
    "plt.imshow(pred[15][0].cpu().detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Machine Learning Models\n",
    "    - To fit the data formats of tensors, every sci-kit learn model needs to be wrapped inside the object MLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLWrapper(nn.Module):\n",
    "    def __init__(self, model_object = RandomForestRegressor, **args):\n",
    "        self.model = model_object(**args)\n",
    "        self.device = torch.device('cpu')\n",
    "    def loader_to_xy(self, loader):\n",
    "        x, y = loader.dataset.tensors\n",
    "        x, y = np.array(x).squeeze(1), np.array(y)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        return x, y\n",
    "    def fit(self, train_loader, val_loader):\n",
    "        train_x, train_y = self.loader_to_xy(train_loader)\n",
    "        val_train_x, val_train_y = self.loader_to_xy(val_loader)\n",
    "        self.model.fit(train_x, train_y)\n",
    "        accu = self.model.score(val_train_x, val_train_y)\n",
    "        print(accu)\n",
    "    def inference(self, img):\n",
    "        batch_size, _, _, _ = img.shape\n",
    "        img = img.reshape(batch_size, -1)\n",
    "        return torch.tensor(self.model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_CHANNELS = 1    # For grayscale images; use 3 for RGB.\n",
    "N_EPOCHS = 100      # Adjust as needed.\n",
    "LATENT_DIM = 300    # Dimensionality of the latent space.\n",
    "FEATURE_MAPS = 8    # Base number of feature maps.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConditionalSegmentationVAE(\n",
    "    latent_dim=LATENT_DIM,\n",
    "    width=WIDTH,\n",
    "    height=HEIGHT,\n",
    "    img_channels=IMG_CHANNELS,\n",
    "    feature_maps=FEATURE_MAPS,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "segmentation_loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "# Assume your train_loader and val_loader are defined appropriately.\n",
    "model.train_vae(\n",
    "    train_loader=loader,       # your training DataLoader\n",
    "    val_loader=val_loader,       # your validation DataLoader\n",
    "    n_epochs=N_EPOCHS,\n",
    "    seg_criterion=segmentation_loss_fn,\n",
    "    kl_weight=0.001,\n",
    "    patience=10,\n",
    "    device=device\n",
    ")\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluate_and_plot(test_loader, model=model, encoder=encoder, title='VAE', dataset_name=city_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = MLWrapper()\n",
    "model.fit(loader, val_loader)\n",
    "evaluate_and_plot(test_loader, model=model, encoder=encoder, title='RF', dataset_name=city_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
